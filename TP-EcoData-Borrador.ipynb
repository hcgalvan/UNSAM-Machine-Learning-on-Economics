{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos del TP\n",
    "*   Explorar los datos\n",
    "*   Plantear el problema a resolver\n",
    "*   Preprocesar los datos a un formato adecuado\n",
    "*   Elegir algoritmos\n",
    "*   Fittear y validar\n",
    "*   Decidir el algoritmo final, y testear\n",
    "\n",
    "# Problemas que se buscan resolver:\n",
    "\n",
    "Se ha demostrado que cada vez más empresas (especialmente empresas de comercio electrónico) tienen grandes dificultades en la conversión de propects (clientes potencialess) a clientes activos con la primer compra, además sostener a los clientes actuales en la dinámica e interacción en el tiempo con los productos y la empresa suele ser de difícil comprensión, generando pérdidas de facturación por cancelaciones hasta la pérdida del cliente\n",
    "\n",
    "Las investigaciones se han centrado en el análisis del producto y el ciclo de valor del cliente en la empresa.\n",
    "\n",
    "Las preguntas que ayudan a entender el problema:\n",
    "¿Cuál es el rendimiento de los productos en las ventas?\n",
    "¿Cómo se relacionan los clientes con los productos en el tiempo?\n",
    "¿Cómo se agrupan los clientes según sus necesidades e intereses?\n",
    "¿Cómo retenemos a clientes o mejoramos las tasas de conversión a clientes ? \n",
    "\n",
    "## OBJETIVO:\n",
    "Este proyecto tiene como objetivo explorar diferentes herramientas de conversion, retención y rendimientos de clientes en las ventas a traves de metodologías de Machine Learning\n",
    "\n",
    "Exploraremos y mediremos la efectividad de las siguientes herramientas:\n",
    "A. Product Analytics.\n",
    "B. Recomendación de Productos\n",
    "C. CLV (Ciclo de vida del Valor cliente)\n",
    "D. Segmentación de clientes.\n",
    "\n",
    "Las técnicas algorítmicas en ML a utilizar y explorar:\n",
    "* No supervisados\n",
    "  * Clustering Knn\n",
    "* Supervidados\n",
    "  * Decision Tree, \n",
    "  * SVM, ANN, DNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AED - Exploración de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime, timedelta, date\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo 1\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estas en Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETAIL_PATH = \"https://github.com/hcgalvan/UNSAM-Machine-Learning-on-Economics/raw/main/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "  def load_datasets_h1(datasets_path=RETAIL_PATH):\n",
    "    csv_path = os.path.join(datasets_path, \"Year 2009-2010_train.csv\")\n",
    "    return pd.read_csv(csv_path, encoding= 'unicode_escape')\n",
    "\n",
    "  retail_ol_h1 = load_datasets_h1()\n",
    "  def load_datasets_h2(datasets_path=RETAIL_PATH):\n",
    "      csv_path = os.path.join(datasets_path, \"Year 2010-2011_train.csv\")\n",
    "      return pd.read_csv(csv_path, encoding= 'unicode_escape')\n",
    "\n",
    "  retail_ol_h2 = load_datasets_h2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar si estas en PC con Code y cualquier otro framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_ol_h1 = pd.read_csv('./data/Year 2009-2010_train.csv',  encoding= 'unicode_escape')\n",
    "retail_ol_h2 = pd.read_csv('./data/Year 2010-2011_train.csv',  encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De Uso comun para PC y Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [retail_ol_h1, retail_ol_h2]\n",
    "results = pd.concat(frames)\n",
    "df = results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situación actual de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853896, 9)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "Invoice             0\n",
       "StockCode           0\n",
       "Description      3531\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "Price               0\n",
       "Customer ID    194467\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeamos datos unicos y actuales en cada features (atributos).\n",
    "\n",
    "for i in df.columns:\n",
    "  print(\"Actual number of values\",i,len(df[i]))\n",
    "  print(\"Unique number of values\",i,len(df[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "Invoice             0\n",
       "StockCode           0\n",
       "Description      3531\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "Price               0\n",
       "Customer ID    194467\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos valores nulos en los features\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos datos duplicados\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango de Fecha: 2009-12-01 07:45:00 ~ 2011-12-09 12:50:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2600, 9)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meses incompletos\n",
    "print('Rango de Fecha: %s ~ %s' % (df['InvoiceDate'].min(), df['InvoiceDate'].max()))\n",
    "df.loc[df['InvoiceDate'] >= '2011-12-01'].shape\n",
    "df.loc[df['InvoiceDate'] < '2009-12-02' ].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de Datos\n",
    "1. Eliminación de pedidos cancelados.\n",
    "2. Eliminando registros sin Customer ID, sin descripción de productos y features sin títulos\n",
    "3. Excluimos meses incompletos.\n",
    "4. Calcular las ventas totales de los features Cantidad y Precio unitario.\n",
    "5. Datos por cliente : para analizar segmentos de clientes, necesitamos transformar nuestros datos, de modo que cada registro represente el historial de compras de clientes individuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Limpieza de Datos\n",
    "Hay registros con valores negativos en la columna Cantidad, que representan pedidos cancelados. Ignoremos y eliminemos estos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_datos(df):\n",
    "    # Observamos las cantidades negativas\n",
    "    df.loc[df['Quantity'] <= 0].shape\n",
    "    df = df.loc[df['Quantity'] > 0]\n",
    "    #Quitamos la 1er columna vacía\n",
    "    df.drop(['Unnamed: 0'], axis =1, inplace=True)\n",
    "    # Quitamos valores nulos en features Customer ID y la Descripcion porque no son imputaciones.\n",
    "    df.dropna(inplace=True)\n",
    "    # Quitamos valores duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Quitamos fechas incompletas\n",
    "    df = df.loc[df['InvoiceDate'] < '2011-12-01']\n",
    "    df = df.loc[df['InvoiceDate'] > '2009-12-01']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Agregados de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP - PRE-PROCESADO PARA ANALIZAR CATEGORIAS DE PRODUCTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función busca categorizar a los productos que se ofrecen\n",
    "def agrega_color(df):\n",
    "    colours = ['red','orange', 'yellow','green', 'blue', 'indigo', 'violet', 'purple', 'pink', 'silver', 'gold', 'beige', 'brown', 'grey', 'gray', 'black', 'white', 'cream']\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    Product_type = []\n",
    "    Colour_type = []\n",
    "    dataset= df\n",
    "    # dataset= len(df)\n",
    "    for row in dataset.iloc[:,2]:\n",
    "        s=\" \"\n",
    "        description = re.sub('[^a-zA-Z]',\" \", str(row).lower()) #cleaning of text data\n",
    "        wordsList = nltk.word_tokenize(description) #tokenization\n",
    "        wordsList = [nltk.stem.WordNetLemmatizer().lemmatize(w, 'n') for w in wordsList if not w in stop_words] # lemmitization\n",
    "        flag=False\n",
    "        for w in wordsList:\n",
    "            if w in colours:\n",
    "                Colour_type.append(w)\n",
    "                flag=True\n",
    "            break\n",
    "        if flag==False:\n",
    "            Colour_type.append(\"no_color\") #taking out colours from description\n",
    "\n",
    "        tagged = nltk.pos_tag(wordsList)\n",
    "\n",
    "        for tag in tagged:\n",
    "            if tag[1]=='NN' :\n",
    "                s+=tag[0] +  \" \"\n",
    "        Product_type.append(s)\n",
    "    \n",
    "    return Product_type, Colour_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borrar_desc_invoice(df):\n",
    "    # Quitar columnas \"InvoiceDate\" y \"Description\"\n",
    "    X = df.drop([\"Description\", \"InvoiceDate\"], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_tipo_datos(df):\n",
    "    # Transformar todas las variables en categoricas y en flotantes \n",
    "    # Columna 2 es Quantity, 3 es Price y 8 Revenue\n",
    "    X = df.astype('category')\n",
    "    X.iloc[:, 2] = X.iloc[:, 2].astype(float)\n",
    "    X.iloc[:, 3] = X.iloc[:, 3].astype(float)\n",
    "    X.iloc[:, 8] = X.iloc[:, 8].astype(float)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCIONES UTILIZADAS EN GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos formato de fecha a InvoiceDate para realizar tratamientos posteriores\n",
    "def tipos_dataset(df):    \n",
    "    df['InvoiceDate']  = pd.to_datetime(df.InvoiceDate, format = '%Y/%m/%d %H:%M')\n",
    "    df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "    df['Price']=df['Price'].astype(str)\n",
    "    df['Price']=df['Price'].astype(float)\n",
    "    df['Month'] = pd.DatetimeIndex(pd.to_datetime(df['InvoiceDate'])).month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos features para Analizar diferentes casos\n",
    "# UTILIZAR UNA VEZ SETEADO LOS TIPOS DE DATOS def tipos_dataset(df)\n",
    "def agregados_features(df):\n",
    "    # Agregamos features Sales\n",
    "    df['Sales'] = df['Quantity'] * df['Price']\n",
    "    # Datos cliente por pedido\n",
    "    df['date'] = pd.to_datetime(df.InvoiceDate.dt.date, errors='coerce')\n",
    "    df['time'] = df.InvoiceDate.dt.time\n",
    "    df['hour'] = df['time'].apply(lambda x: x.hour)\n",
    "\n",
    "    df['day'] = df['time'].apply(lambda x: x.day)\n",
    "    df['month'] = df['time'].apply(lambda x: x.month)\n",
    "    df['year'] = df['time'].apply(lambda x: x.year)\n",
    "    \n",
    "    df['weekend'] = df['date'].apply(lambda x: x.weekday() in [5, 6])\n",
    "    df['dayofweek'] = df['date'].apply(lambda x: x.dayofweek)\n",
    "\n",
    "    df['Product Type'] = agrega_color(df)[0]\n",
    "    df['Colour_type']= agrega_color(df)[1]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_fechas(df):\n",
    "\n",
    "    df['Day'] = df['time'].apply(lambda x: x.day)\n",
    "    df['Month'] = df['time'].apply(lambda x: x.month)\n",
    "    df['Year'] = df['time'].apply(lambda x: x.year)\n",
    "    df['DayOfWeek'] = df['date'].apply(lambda x: x.dayofweek)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función agrupa por continente a paises y suma la cantidad vendida por pais\n",
    "def cantidad_mensual_pais(df):\n",
    "    df = df.groupby(['Country' , 'Month']).agg({'Quantity':'sum'})\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by=['Month'])\n",
    "    Europe = ['United Kingdom','France', 'Belgium','EIRE',\n",
    "              'Germany','Portugal', 'Denmark', 'Netherlands', 'Poland',\n",
    "             'Spain', 'Cyprus', 'Greece', 'Norway', 'Austria', 'Sweden', \n",
    "              'Finland','Italy', 'Switzerland', 'Malta', 'Israel', \n",
    "              'Lithuania','Iceland']\n",
    "    Asia = [ 'Japan','United Arab Emirates','Singapore','Hong Kong',\n",
    "       'Thailand','West Indies', 'Korea','Lebanon',]\n",
    "    America = ['Channel Islands','USA','Brazil', 'Canada']\n",
    "    Australia = ['Australia',]\n",
    "    df['Continent'] = df['Country'].map(lambda x: 'Europe' if x in Europe else(\n",
    "                                        'Asia' if x in Asia else\n",
    "                                        'America' if x in America else\n",
    "                                        'Australia' if x in Australia else 'None' ))\n",
    "    fig = px.scatter_geo(df, locations=\"Country\",color=\"Continent\",\n",
    "                         hover_name=\"Country\", size=\"Quantity\",\n",
    "                         animation_frame=\"Month\",\n",
    "                         projection=\"natural earth\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCIONES SOBRE PRECIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteo Cantidad y precio\n",
    "def ploteo_precio_cantidad(df):\n",
    "    df = df[['Quantity','Price']]\n",
    "    df['PriceBins'] = pd.cut(df['Price'].tolist(), bins=8)\n",
    "    sns.barplot(data=df,x=\"PrecioBins\", y=\"Cantidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuántos clientes compraron algo cada mes durante el último año\n",
    "def price_customer(df):\n",
    "    \n",
    "    df = df.groupby(['Country' , 'Month']).agg({'Price':'sum' , 'Customer ID' :'count'})\n",
    "    df.columns = ['PriceSum','CustomerIDCount']\n",
    "    df = df.reset_index()\n",
    "    cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "    pvd = pd.pivot_table(df, values='CustomerIDCount', index=['Country'],\n",
    "                    columns=['Month'],\n",
    "                    aggfunc=np.sum).fillna(0)\n",
    "    return pvd.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿En qué rangos los precios son más comunes? - Grafica\n",
    "def rango_precios(df):\n",
    "    prices = pd.DataFrame([df['Price'].value_counts()\n",
    "                         .sort_values(ascending=False).to_dict()]).T\n",
    "    df = pd.DataFrame(df['Price'].value_counts())\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['Price','CountPrice']\n",
    "    df['PriceBins'] = pd.cut(df['Price'].tolist(), bins=8)\n",
    "    sns.barplot(data=df, x='PriceBins', y='CountPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango de cambio de precio durante el tiempo - EXPLORACION DE DATOS\n",
    "def AED(df):\n",
    "     customer_avg_spending= df[['Price','Customer ID', 'InvoiceDate' , 'Country']]\n",
    "     avg_selling_of_products = df[['Price','Quantity','InvoiceDate']]\n",
    "     return customer_avg_spending, avg_selling_of_products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_avg_spending_insights(df):\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']).dt.strftime('%Y-%m-%d')\n",
    "    df = df.groupby(['InvoiceDate']).agg({'Price':'sum'}).reset_index()\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns = ['Date','PriceSum']\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df['Date'], y=df['PriceSum'], name=\"Price Sum\",\n",
    "                         line_color='deepskyblue'))\n",
    "    fig.update_layout(title_text='Sum range of all prices among time',\n",
    "                  xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCIONES QUE HACEN AGREGACIONES Y MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_cliente_item(df):\n",
    "    # Matriz cliente-item\n",
    "    # Podemos sumar todas las cantidades compradas para cada artículo, utilizando la función aggfunc.\n",
    "    customer_item_matrix = df.pivot_table(\n",
    "        index='Customer ID', \n",
    "        columns='StockCode', \n",
    "        values='Quantity',\n",
    "        aggfunc='sum'\n",
    "    )\n",
    "    #Convertimos esta matriz y lo codificamos en 0 - 1 a los datos, por lo que el valor de 1 determinando un producto fue comprado por el cliente dado, y el valor 0 determinado por producto que nunca fue comprado por el cliente dado.\n",
    "    # La función Lambda que estamos usando en este código simplemente codifica todos los elementos cuyos valores son mayores que 0 con 1, y el resto con 0.\n",
    "    customer_item_matrix = customer_item_matrix.applymap(lambda x: 1 if x > 0 else 0)\n",
    "    return customer_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupa_cliente_pedidos(df):\n",
    "    orders_df = df.groupby(['Customer ID', 'Invoice']).agg({\n",
    "    'Sales': sum,\n",
    "    'InvoiceDate': max\n",
    "    })\n",
    "    return orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupa_cliente_ventas(df):\n",
    "    # Datos cliente por ventas\n",
    "    customer_df = df.groupby('Customer ID').agg({\n",
    "        'Sales': sum,\n",
    "        'Invoice': lambda x: x.nunique()\n",
    "    })\n",
    "\n",
    "    customer_df.columns = ['TotalSales', 'OrderCount']\n",
    "    customer_df['AvgOrderValue'] = customer_df['TotalSales']/customer_df['OrderCount']\n",
    "    return customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Datos por cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantanea de la matriz\n",
    "customer_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = customer_df.rank(method='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis descriptivo de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos convertir InvoiceDate en tipo Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>613951</td>\n",
       "      <td>613951</td>\n",
       "      <td>613951</td>\n",
       "      <td>613951</td>\n",
       "      <td>613951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>35540</td>\n",
       "      <td>4605</td>\n",
       "      <td>5243</td>\n",
       "      <td>33316</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>576339</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>2011-11-14 15:27:00</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>434</td>\n",
       "      <td>4051</td>\n",
       "      <td>4051</td>\n",
       "      <td>434</td>\n",
       "      <td>551712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Invoice StockCode                         Description  \\\n",
       "count   613951    613951                              613951   \n",
       "unique   35540      4605                                5243   \n",
       "top     576339    85123A  WHITE HANGING HEART T-LIGHT HOLDER   \n",
       "freq       434      4051                                4051   \n",
       "\n",
       "                InvoiceDate         Country  \n",
       "count                613951          613951  \n",
       "unique                33316              41  \n",
       "top     2011-11-14 15:27:00  United Kingdom  \n",
       "freq                    434          551712  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptiva de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    613951.000000\n",
       "mean      15322.031318\n",
       "std        1695.361076\n",
       "min       12346.000000\n",
       "25%       13971.000000\n",
       "50%       15251.000000\n",
       "75%       16794.000000\n",
       "max       18287.000000\n",
       "Name: Customer ID, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizamos clientes\n",
    "df['Customer ID'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    613951.000000\n",
       "mean         13.385628\n",
       "std         119.300741\n",
       "min           1.000000\n",
       "25%           2.000000\n",
       "50%           6.000000\n",
       "75%          12.000000\n",
       "max       74215.000000\n",
       "Name: Quantity, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Quantity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalSales</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>AvgOrderValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2327.814351</td>\n",
       "      <td>6.098147</td>\n",
       "      <td>302.795982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11403.148921</td>\n",
       "      <td>12.491479</td>\n",
       "      <td>474.321604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>276.365000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>143.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>684.745000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>227.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1810.440000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>340.546941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>460080.010000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>19633.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TotalSales   OrderCount  AvgOrderValue\n",
       "count    5828.000000  5828.000000    5828.000000\n",
       "mean     2327.814351     6.098147     302.795982\n",
       "std     11403.148921    12.491479     474.321604\n",
       "min         0.000000     1.000000       0.000000\n",
       "25%       276.365000     1.000000     143.100000\n",
       "50%       684.745000     3.000000     227.097500\n",
       "75%      1810.440000     7.000000     340.546941\n",
       "max    460080.010000   379.000000   19633.500000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalSales</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>AvgOrderValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2914.500000</td>\n",
       "      <td>2914.500000</td>\n",
       "      <td>2914.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1682.543016</td>\n",
       "      <td>1682.543016</td>\n",
       "      <td>1682.543016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1457.750000</td>\n",
       "      <td>1457.750000</td>\n",
       "      <td>1457.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2914.500000</td>\n",
       "      <td>2914.500000</td>\n",
       "      <td>2914.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4371.250000</td>\n",
       "      <td>4371.250000</td>\n",
       "      <td>4371.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TotalSales   OrderCount  AvgOrderValue\n",
       "count  5828.000000  5828.000000    5828.000000\n",
       "mean   2914.500000  2914.500000    2914.500000\n",
       "std    1682.543016  1682.543016    1682.543016\n",
       "min       1.000000     1.000000       1.000000\n",
       "25%    1457.750000  1457.750000    1457.750000\n",
       "50%    2914.500000  2914.500000    2914.500000\n",
       "75%    4371.250000  4371.250000    4371.250000\n",
       "max    5828.000000  5828.000000    5828.000000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = (rank_df - rank_df.mean()) / rank_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalSales</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>AvgOrderValue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12346.0</th>\n",
       "      <td>1.723284</td>\n",
       "      <td>1.244842</td>\n",
       "      <td>1.729228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347.0</th>\n",
       "      <td>1.327455</td>\n",
       "      <td>0.859711</td>\n",
       "      <td>1.405313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348.0</th>\n",
       "      <td>0.814541</td>\n",
       "      <td>0.491221</td>\n",
       "      <td>0.844852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349.0</th>\n",
       "      <td>1.310219</td>\n",
       "      <td>0.203561</td>\n",
       "      <td>1.633539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350.0</th>\n",
       "      <td>-0.960154</td>\n",
       "      <td>-1.731605</td>\n",
       "      <td>0.246948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12351.0</th>\n",
       "      <td>-0.897748</td>\n",
       "      <td>-1.731011</td>\n",
       "      <td>0.392561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12352.0</th>\n",
       "      <td>1.111116</td>\n",
       "      <td>1.174710</td>\n",
       "      <td>0.254674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12353.0</th>\n",
       "      <td>-0.667145</td>\n",
       "      <td>-0.747381</td>\n",
       "      <td>-0.585126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12354.0</th>\n",
       "      <td>0.085882</td>\n",
       "      <td>-1.730416</td>\n",
       "      <td>1.572322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12355.0</th>\n",
       "      <td>0.122731</td>\n",
       "      <td>-0.746786</td>\n",
       "      <td>1.081399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12356.0</th>\n",
       "      <td>1.436219</td>\n",
       "      <td>0.491815</td>\n",
       "      <td>1.654341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12357.0</th>\n",
       "      <td>1.673954</td>\n",
       "      <td>-0.185136</td>\n",
       "      <td>1.728039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12358.0</th>\n",
       "      <td>1.131323</td>\n",
       "      <td>0.204155</td>\n",
       "      <td>1.527747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12359.0</th>\n",
       "      <td>1.536068</td>\n",
       "      <td>1.175304</td>\n",
       "      <td>1.539039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360.0</th>\n",
       "      <td>1.272776</td>\n",
       "      <td>0.860305</td>\n",
       "      <td>1.330427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TotalSales  OrderCount  AvgOrderValue\n",
       "Customer ID                                       \n",
       "12346.0        1.723284    1.244842       1.729228\n",
       "12347.0        1.327455    0.859711       1.405313\n",
       "12348.0        0.814541    0.491221       0.844852\n",
       "12349.0        1.310219    0.203561       1.633539\n",
       "12350.0       -0.960154   -1.731605       0.246948\n",
       "12351.0       -0.897748   -1.731011       0.392561\n",
       "12352.0        1.111116    1.174710       0.254674\n",
       "12353.0       -0.667145   -0.747381      -0.585126\n",
       "12354.0        0.085882   -1.730416       1.572322\n",
       "12355.0        0.122731   -0.746786       1.081399\n",
       "12356.0        1.436219    0.491815       1.654341\n",
       "12357.0        1.673954   -0.185136       1.728039\n",
       "12358.0        1.131323    0.204155       1.527747\n",
       "12359.0        1.536068    1.175304       1.539039\n",
       "12360.0        1.272776    0.860305       1.330427"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalSales</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>AvgOrderValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5828.000000</td>\n",
       "      <td>5.828000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.753504e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.731605</td>\n",
       "      <td>-1.731605</td>\n",
       "      <td>-1.731605e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.865803</td>\n",
       "      <td>-0.865803</td>\n",
       "      <td>-8.658025e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.865803</td>\n",
       "      <td>0.865803</td>\n",
       "      <td>8.658025e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.731605</td>\n",
       "      <td>1.731605</td>\n",
       "      <td>1.731605e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TotalSales   OrderCount  AvgOrderValue\n",
       "count  5828.000000  5828.000000   5.828000e+03\n",
       "mean      0.000000     0.000000  -9.753504e-18\n",
       "std       1.000000     1.000000   1.000000e+00\n",
       "min      -1.731605    -1.731605  -1.731605e+00\n",
       "25%      -0.865803    -0.865803  -8.658025e-01\n",
       "50%       0.000000     0.000000   0.000000e+00\n",
       "75%       0.865803     0.865803   8.658025e-01\n",
       "max       1.731605     1.731605   1.731605e+00"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis más Detallado de productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85123A\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Cuál es el produto más vendido?\n",
    "df.StockCode.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = df[df.StockCode.str.contains(\"85123A\")]\n",
    "product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    WHITE HANGING HEART T-LIGHT HOLDER\n",
       "dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Description.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Precios y Cantidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 613951 entries, 0 to 433525\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Invoice      613951 non-null  object \n",
      " 1   StockCode    613951 non-null  object \n",
      " 2   Description  613951 non-null  object \n",
      " 3   Quantity     613951 non-null  int64  \n",
      " 4   InvoiceDate  613951 non-null  object \n",
      " 5   Price        613951 non-null  float64\n",
      " 6   Customer ID  613951 non-null  float64\n",
      " 7   Country      613951 non-null  object \n",
      " 8   Sales        613951 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 46.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = tipos_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_quantity_plot(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMOS ANALIZADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITMO 1 - CLASIFICACION Y PREDICCIÓN DE CANTIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar datos y establecer tipos\n",
    "df = limpieza_datos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas en Dataframe\n",
    "\n",
    "df['Product Type'] = agrega_color(df)[0]\n",
    "df['Colour_type'] = agrega_color(df)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar Descripcion e Invoice Date\n",
    "df1 = borrar_desc_invoice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar Ingresos por Ventas\n",
    "df1['Revenue'] = df1['Price'] * df1['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding of categorical features\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in [\"Invoice\", \"StockCode\", \"Customer ID\",\"Country\", \"Product Type\",\"Colour_type\"]:\n",
    "  df1[col] = label_encoder.fit_transform(df1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los tipos de datos en categoricos y Float\n",
    "df1 = cambiar_tipo_datos(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitear en dataframe en \"Train\" y \"test\"\n",
    "train, test = train_test_split(df1, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster de items similares para el nuevo feature cluster, utiliza en este caso K-prototype clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeo del valor optimo de 'K' // demanda varios minutos de ejecucion para encontrar el optimo\n",
    "\n",
    "cost = []\n",
    "for num_clusters in list(range(2,15)):\n",
    "    kproto = KPrototypes(n_clusters = num_clusters, init='Cao')\n",
    "    kproto.fit_predict(train, categorical=[0, 1, 4, 5, 6, 7])\n",
    "    cost.append(kproto.cost_)\n",
    "    labels=kproto.labels_\n",
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera un nuevo numero de cluster del atributo\n",
    "\n",
    "kproto = KPrototypes(n_clusters = 3, init = 'Cao')\n",
    "kproto.fit_predict(train, categorical=[0, 1, 4, 5, 6])\n",
    "print(kproto.cost_)\n",
    "labels=kproto.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego nuevo atributo\n",
    "train[\"Cluster number\"]=labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora agrego \"InvoiceDate\" en dataframe\n",
    "\n",
    "df2 = train.merge(pd.DataFrame(df[\"InvoiceDate\"]), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGREGAR AQUI INGENIERIA DE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego las fechas en diferentes rangos: horas, dias, meses, años\n",
    "df2 = agregar_fechas( df2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el proceso en archivo csv\n",
    "df2.to_csv('./data/df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturo el archivo, quito columna vacía y muestro\n",
    "df2 = pd.read_csv('./data/df2.csv')\n",
    "df2.drop(['Unnamed: 0'], axis =1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of test data into number of clusters\n",
    "\n",
    "- Cluster numbers were treated as a target variable as the objective\n",
    "was to match the records from the validation and testing sets with the clusters from the training set.\n",
    "- El numero de Clusters fueron tratados como variable target, con el objetivo de converger los registros del set de validación y testeo con el cluster del set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corte del dataframe entre entrenamiento y validación\n",
    "train_, val_= train_test_split(df2, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_[\"Cluster number\"]\n",
    "train_x=train_.drop(['Cluster number'],axis=1,inplace=False)\n",
    "\n",
    "val_y=val_[\"Cluster number\"]\n",
    "val_x=val_.drop(['Cluster number'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Clasificar\n",
    "* Utilizamos SVC, que brinda el mejor resultado sobre otros algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearSVC()\n",
    "model1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación del data test\n",
    "pred_y = model1.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de Performance\n",
    "accuracy_score(val_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding \"InvoiceDate\" in test data\n",
    "\n",
    "test_Df = test.merge(pd.DataFrame(dataset[\"InvoiceDate\"]), left_index=True, right_index=True)\n",
    "test_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICCION DE FEATURE \"QUANTITY\" PARA DEMANDAS DE PRODUCTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de Label para features categoricos\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in [\"Invoice\", \"StockCode\", \"Customer ID\",\"Country\", \"Product Type\",\"Colour_type\"]:\n",
    "  df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_[\"Quantity\"].astype('int')\n",
    "train_x=train_.drop(['Quantity'], axis=1,inplace=False)\n",
    "\n",
    "test_Df_y=test_Df[\"Quantity\"].astype('int')\n",
    "test_Df_x=test_Df.drop(['Quantity'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,\n",
    "                                                   max_depth=None,\n",
    "                                                   max_features='auto',\n",
    "                                                   max_leaf_nodes=None,\n",
    "                                                   max_samples=None,\n",
    "                                                   min_impurity_decrease=0.0,\n",
    "                                                   min_impurity_split=None,\n",
    "                                                   min_samples_leaf=1,\n",
    "                                                   min_samples_split=2,\n",
    "                                                   min_weight_fraction_leaf=0.0,\n",
    "                                                   n_estimators=100,\n",
    "                                                   n_jobs=None,)\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = clf.predict(test_Df_x)\n",
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_Df_y, prediction_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_Df_y, prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de Hiperparámetros para Algoritmo de Random forest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Numero de arboles en random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Numero de features a considerar en cada split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Numero Maximo de niveles en el arbol\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Numero Minimo de samples requeridos para splitear un nodo\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Numero Minimo de samples requerido por cada hoja nodo\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Método de selección de samples para entrenamiento en cada arbol\n",
    "bootstrap = [True, False]\n",
    "# Crea la cuadrícula (random grid)\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "\n",
    "\n",
    "# Uso del random grid para buscar los mejores hiperparámetros\n",
    "# Primero crea el modelo de base para ajustar\n",
    "rf = RandomForestRegressor()\n",
    "# Busqueda aleatoria de parametros, usando 3 fold cross validation, \n",
    "# search across 100 diferentes combinaciones, y usa todos los nucleos disponibles (available score)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fitea el modelo random search model\n",
    "rf_random.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train_x, train_y)\n",
    "knn=neigh.predict(test_Df_x)\n",
    "print(accuracy_score(test_Df_y, knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC with kernel \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(train_x, train_y)\n",
    "\n",
    "rbf=rbf_svc.predict(test_Df_x)\n",
    "accuracy_score(test_Df_y, rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ad = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ad.fit(train_x, train_y)\n",
    "adb=ad.predict(test_Df_x)\n",
    "print(accuracy_score(test_Df_y, adb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr')\n",
    "lr.fit(train_x, train_y)\n",
    "lrc=lr.predict(test_Df_x)\n",
    "print(accuracy_score(test_Df_y, lrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive base Classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "lr = GaussianNB()\n",
    "lr.fit(train_x, train_y)\n",
    "lrc=lr.predict(test_Df_x)\n",
    "print(accuracy_score(test_Df_y, lrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "dtree_model = DecisionTreeClassifier().fit(train_x, train_y)\n",
    "dtree_predictions = dtree_model.predict(test_Df_x)\n",
    "accuracy_score(test_Df_y, dtree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb=GradientBoostingClassifier()\n",
    "gb.fit(train_x, train_y)\n",
    "gbc=lr.predict(test_Df_x)\n",
    "print(accuracy_score(test_Df_y, gbc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daefe10391fab28efd47c725c790d988bed9ae43bb63bddb4662f55e2c9b1dab"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('codeframe': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
